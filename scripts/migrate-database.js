#!/usr/bin/env node

/**
 * Script de Migra√ß√£o de Dados entre Ambientes MySQL
 * Migra dados de produ√ß√£o para desenvolvimento ou vice-versa
 */

const { PrismaClient } = require('@prisma/client');
const { exec } = require('child_process');
const { promisify } = require('util');
const fs = require('fs');
const path = require('path');

const execAsync = promisify(exec);

class DataMigration {
  constructor() {
    this.stats = {
      migrated: {},
      errors: [],
      skipped: []
    };
    this.config = {
      batchSize: 1000,
      maxRetries: 3,
      timeout: 30000
    };
  }

  async migrateData(sourceConfig, targetConfig, options = {}) {
    console.log('üöÄ Iniciando migra√ß√£o de dados...');

    const sourcePrisma = new PrismaClient({
      datasourceUrl: this.buildConnectionString(sourceConfig)
    });

    const targetPrisma = new PrismaClient({
      datasourceUrl: this.buildConnectionString(targetConfig)
    });

    try {
      await sourcePrisma.$connect();
      await targetPrisma.$connect();
      console.log('‚úÖ Conex√µes estabelecidas');

      // Validar conex√µes
      await this.validateConnections(sourcePrisma, targetPrisma);

      // Obter lista de tabelas
      const tables = await this.getTablesToMigrate(sourcePrisma, options);

      // Executar migra√ß√£o
      for (const table of tables) {
        await this.migrateTable(sourcePrisma, targetPrisma, table, options);
      }

      // Gerar relat√≥rio
      this.generateMigrationReport();

    } catch (error) {
      console.error('‚ùå Erro na migra√ß√£o:', error.message);
      this.stats.errors.push(error.message);
    } finally {
      await sourcePrisma.$disconnect();
      await targetPrisma.$disconnect();
    }

    return this.stats;
  }

  buildConnectionString(config) {
    return `mysql://${config.user}:${config.password}@${config.host}:${config.port || 3306}/${config.database}`;
  }

  async validateConnections(sourcePrisma, targetPrisma) {
    console.log('\nüîç Validando conex√µes...');

    try {
      // Testar conex√£o source
      await sourcePrisma.$queryRaw`SELECT 1`;
      console.log('‚úÖ Conex√£o source OK');

      // Testar conex√£o target
      await targetPrisma.$queryRaw`SELECT 1`;
      console.log('‚úÖ Conex√£o target OK');

    } catch (error) {
      throw new Error(`Falha na valida√ß√£o de conex√µes: ${error.message}`);
    }
  }

  async getTablesToMigrate(sourcePrisma, options) {
    console.log('\nüìã Obtendo lista de tabelas...');

    let tables = [
      'usuario', 'empresa', 'usuarioPermissao', 'passwordResetToken',
      'sessaoUsuario', 'cor', 'familia', 'tamanho', 'deposito',
      'uNEG', 'sKU', 'representante', 'cliente', 'fornecedor',
      'transportadora', 'tabelaDinamica'
    ];

    // Filtrar tabelas se especificado
    if (options.tables && options.tables.length > 0) {
      tables = tables.filter(table => options.tables.includes(table));
      console.log(`üìã Migrando apenas tabelas: ${tables.join(', ')}`);
    } else {
      console.log(`üìã Migrando todas as tabelas: ${tables.length} tabelas`);
    }

    // Verificar se tabelas existem
    const existingTables = [];
    for (const table of tables) {
      try {
        await sourcePrisma.$queryRaw`SELECT 1 FROM ${sourcePrisma.$queryRaw(table)} LIMIT 1`;
        existingTables.push(table);
      } catch (error) {
        console.warn(`‚ö†Ô∏è  Tabela ${table} n√£o encontrada, pulando...`);
        this.stats.skipped.push(table);
      }
    }

    return existingTables;
  }

  async migrateTable(sourcePrisma, targetPrisma, tableName, options) {
    console.log(`\nüîÑ Migrando tabela: ${tableName}`);

    try {
      // Contar registros na origem
      const sourceCount = await sourcePrisma[tableName].count();
      console.log(`üìä Registros na origem: ${sourceCount}`);

      if (sourceCount === 0) {
        console.log(`‚è≠Ô∏è  Tabela ${tableName} vazia, pulando...`);
        this.stats.migrated[tableName] = 0;
        return;
      }

      // Limpar tabela de destino se solicitado
      if (options.truncate !== false) {
        await targetPrisma.$executeRaw`TRUNCATE TABLE ${targetPrisma.$queryRaw(tableName)}`;
        console.log(`üóëÔ∏è  Tabela ${tableName} limpa no destino`);
      }

      // Migrar dados em lotes
      let migrated = 0;
      let offset = 0;

      while (offset < sourceCount) {
        const batch = await sourcePrisma[tableName].findMany({
          skip: offset,
          take: this.config.batchSize,
          orderBy: { id: 'asc' }
        });

        if (batch.length === 0) break;

        // Inserir lote no destino
        await this.insertBatch(targetPrisma, tableName, batch);

        migrated += batch.length;
        offset += batch.length;

        console.log(`   üì¶ Lote ${Math.floor(offset / this.config.batchSize) + 1}: ${batch.length} registros`);

        // Pequena pausa para n√£o sobrecarregar
        await new Promise(resolve => setTimeout(resolve, 100));
      }

      this.stats.migrated[tableName] = migrated;
      console.log(`‚úÖ Tabela ${tableName} migrada: ${migrated} registros`);

    } catch (error) {
      console.error(`‚ùå Erro ao migrar ${tableName}:`, error.message);
      this.stats.errors.push(`${tableName}: ${error.message}`);
    }
  }

  async insertBatch(targetPrisma, tableName, batch) {
    // Usar transa√ß√£o para inser√ß√£o em lote
    await targetPrisma.$transaction(async (tx) => {
      for (const record of batch) {
        // Remover campos de timestamp se necess√°rio
        const cleanRecord = { ...record };
        delete cleanRecord.createdAt;
        delete cleanRecord.updatedAt;

        await tx[tableName].create({ data: cleanRecord });
      }
    });
  }

  generateMigrationReport() {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-').substring(0, 19);
    const reportFile = `./migration_report_${timestamp}.json`;

    const totalMigrated = Object.values(this.stats.migrated).reduce((sum, val) => sum + val, 0);

    const report = {
      timestamp: new Date().toISOString(),
      summary: {
        totalTables: Object.keys(this.stats.migrated).length,
        totalRecords: totalMigrated,
        skippedTables: this.stats.skipped.length,
        errorCount: this.stats.errors.length,
        status: this.stats.errors.length === 0 ? 'success' : 'completed_with_errors'
      },
      migrated: this.stats.migrated,
      skipped: this.stats.skipped,
      errors: this.stats.errors
    };

    // Salvar relat√≥rio
    fs.writeFileSync(reportFile, JSON.stringify(report, null, 2), 'utf8');

    console.log('\nüìä RELAT√ìRIO DE MIGRA√á√ÉO');
    console.log('='.repeat(50));
    console.log(`üìã Tabelas migradas: ${report.summary.totalTables}`);
    console.log(`üìä Registros migrados: ${report.summary.totalRecords}`);
    console.log(`‚è≠Ô∏è  Tabelas puladas: ${report.summary.skippedTables}`);
    console.log(`‚ùå Erros: ${report.summary.errorCount}`);
    console.log(`üìÑ Relat√≥rio salvo em: ${reportFile}`);

    if (report.summary.status === 'success') {
      console.log('\nüéâ Migra√ß√£o conclu√≠da com SUCESSO!');
    } else {
      console.log('\n‚ö†Ô∏è  Migra√ß√£o conclu√≠da com alguns erros!');
      console.log('Verifique o relat√≥rio para detalhes.');
    }
  }

  // M√©todo para migra√ß√£o via mysqldump (mais r√°pido para grandes volumes)
  async migrateViaDump(sourceConfig, targetConfig, options = {}) {
    console.log('üöÄ Iniciando migra√ß√£o via dump...');

    const timestamp = new Date().toISOString().replace(/[:.]/g, '-').substring(0, 19);
    const dumpFile = `./migration_dump_${timestamp}.sql`;

    try {
      // Criar dump da origem
      console.log('üì§ Criando dump da origem...');
      const dumpCommand = `mysqldump -h ${sourceConfig.host} -u ${sourceConfig.user} -p${sourceConfig.password} ${sourceConfig.database} > ${dumpFile}`;

      await execAsync(dumpCommand);
      console.log(`‚úÖ Dump criado: ${dumpFile}`);

      // Importar para o destino
      console.log('üì• Importando para o destino...');
      const importCommand = `mysql -h ${targetConfig.host} -u ${targetConfig.user} -p${targetConfig.password} ${targetConfig.database} < ${dumpFile}`;

      await execAsync(importCommand);
      console.log('‚úÖ Dados importados com sucesso');

      // Limpar arquivo de dump
      if (options.keepDump !== true) {
        fs.unlinkSync(dumpFile);
        console.log('üóëÔ∏è  Arquivo de dump removido');
      }

      return { status: 'success', dumpFile };

    } catch (error) {
      console.error('‚ùå Erro na migra√ß√£o via dump:', error.message);

      // Limpar arquivo de dump em caso de erro
      if (fs.existsSync(dumpFile)) {
        fs.unlinkSync(dumpFile);
      }

      throw error;
    }
  }
}

// Fun√ß√£o principal
async function main() {
  const args = process.argv.slice(2);

  if (args.length < 2) {
    console.log(`
üöÄ Migra√ß√£o de Dados MySQL

Uso: node migrate-database.js <source-config> <target-config> [op√ß√µes]

Configura√ß√µes devem ser arquivos JSON ou vari√°veis de ambiente:
  - Arquivo JSON: caminho para arquivo com {host, user, password, database, port?}
  - Ambiente: usar DB_SOURCE_* e DB_TARGET_* vari√°veis

Op√ß√µes:
  --tables table1,table2    Migrar apenas tabelas espec√≠ficas
  --no-truncate             N√£o truncar tabelas de destino
  --use-dump                Usar mysqldump (mais r√°pido)
  --keep-dump               Manter arquivo de dump ap√≥s migra√ß√£o
  --help                    Mostrar esta ajuda

Exemplos:
  node migrate-database.js config/source.json config/target.json
  node migrate-database.js config/source.json config/target.json --tables usuario,empresa
  node migrate-database.js config/source.json config/target.json --use-dump
`);
    process.exit(1);
  }

  const sourceConfigPath = args[0];
  const targetConfigPath = args[1];

  // Carregar configura√ß√µes
  let sourceConfig, targetConfig;

  try {
    if (fs.existsSync(sourceConfigPath)) {
      sourceConfig = JSON.parse(fs.readFileSync(sourceConfigPath, 'utf8'));
    } else {
      // Usar vari√°veis de ambiente
      sourceConfig = {
        host: process.env.DB_SOURCE_HOST,
        user: process.env.DB_SOURCE_USER,
        password: process.env.DB_SOURCE_PASSWORD,
        database: process.env.DB_SOURCE_DATABASE,
        port: process.env.DB_SOURCE_PORT
      };
    }

    if (fs.existsSync(targetConfigPath)) {
      targetConfig = JSON.parse(fs.readFileSync(targetConfigPath, 'utf8'));
    } else {
      // Usar vari√°veis de ambiente
      targetConfig = {
        host: process.env.DB_TARGET_HOST,
        user: process.env.DB_TARGET_USER,
        password: process.env.DB_TARGET_PASSWORD,
        database: process.env.DB_TARGET_DATABASE,
        port: process.env.DB_TARGET_PORT
      };
    }
  } catch (error) {
    console.error('‚ùå Erro ao carregar configura√ß√µes:', error.message);
    process.exit(1);
  }

  // Processar op√ß√µes
  const options = {
    truncate: true,
    useDump: false,
    keepDump: false,
    tables: null
  };

  for (let i = 2; i < args.length; i++) {
    const arg = args[i];
    switch (arg) {
      case '--no-truncate':
        options.truncate = false;
        break;
      case '--use-dump':
        options.useDump = true;
        break;
      case '--keep-dump':
        options.keepDump = true;
        break;
      case '--tables':
        if (i + 1 < args.length) {
          options.tables = args[i + 1].split(',');
          i++; // Pular pr√≥ximo argumento
        }
        break;
    }
  }

  const migration = new DataMigration();

  try {
    if (options.useDump) {
      await migration.migrateViaDump(sourceConfig, targetConfig, options);
    } else {
      await migration.migrateData(sourceConfig, targetConfig, options);
    }
  } catch (error) {
    console.error('‚ùå Migra√ß√£o falhou:', error.message);
    process.exit(1);
  }
}

// Executar se chamado diretamente
if (require.main === module) {
  main().catch(error => {
    console.error('‚ùå Erro fatal:', error);
    process.exit(1);
  });
}

module.exports = { DataMigration };